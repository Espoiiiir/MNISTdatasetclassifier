{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BzVyMVLuXDoh"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from tqdm import tqdm\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6QXXv7cXEVj",
        "outputId": "1b73bb15-ccd1-4614-d5f0-33c0897a8cc4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Establish our transform\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "# Load train and test datasets\n",
        "trainval_dataset = datasets.MNIST(root=\"data\", train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST(root=\"data\", train=False, download=True, transform=transform)\n",
        "\n",
        "train_len = int(len(trainval_dataset) * 0.8)\n",
        "val_len = len(trainval_dataset) - train_len\n",
        "\n",
        "train_subset, val_subset = torch.utils.data.random_split(\n",
        "    trainval_dataset, [train_len, val_len], generator=torch.Generator().manual_seed(42)\n",
        ")\n",
        "# Create the training and test dataloaders with a batch size of 64\n",
        "batch_size = 64\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    dataset=train_subset, shuffle=True, batch_size=batch_size)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    dataset=val_subset, shuffle=False, batch_size=batch_size)\n",
        "\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
      ],
      "metadata": {
        "id": "gbemOMnnXEYU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f74a5fb-2253-4269-cab9-3906955a4437"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 15861466.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 482416.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 4369196.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 3577564.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The specific pre-processing steps applied here are:**\n",
        "ToTensor: This converts the data samples from their original format (likely integers representing pixel values) into tensors, which are a fundamental data structure used in machine learning frameworks like PyTorch.\n",
        "\n",
        "Normalize: This transformation normalizes the pixel values of the images to a range between 0 and 1. This is a common step in image classification tasks as it helps improve the training speed and stability of the model."
      ],
      "metadata": {
        "id": "xJ75B8o_YFRg"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d9w0Gne-wB9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a batch of data from the train_loader\n",
        "dataiter = iter(test_loader)\n",
        "images, labels = next(dataiter)\n",
        "# print the type and shape od images and labels\n",
        "print(type(images))\n",
        "print(images.shape)\n",
        "print(labels.shape)\n",
        "# Plot multiple images from the batch\n",
        "fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(10, 10))\n",
        "for i, ax in enumerate(axes.flat):\n",
        "  # Select a single image from the batch\n",
        "  image = images[i]\n",
        "\n",
        "  # Reshape the image if necessary (assuming it's already a tensor)\n",
        "  # image = image.view(-1, 28, 28)\n",
        "\n",
        "  # Display the image\n",
        "  ax.imshow(image.squeeze(), cmap='gray')  # Squeeze to remove channel dimension\n",
        "  ax.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "mhlqxVj7ZBTk",
        "outputId": "234d3e36-d161-4798-8268-e16bfa09d3ca"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Improved model architecture implementing Dropout."
      ],
      "metadata": {
        "id": "JZM23IFtwS8P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the neural network architecture\n",
        "net = nn.Sequential(\n",
        "                      # Add linear layer\n",
        "                      nn.Linear(784, 256),\n",
        "                      # add hidden layer, with relu activation function\n",
        "                      # Dropout to avoid overfitting\n",
        "                      nn.ReLU(),\n",
        "                      nn.Dropout(0.2),\n",
        "                      nn.Linear(256, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Dropout(0.2),\n",
        "                      nn.Linear(128, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Dropout(0.2),\n",
        "                      # add output layer, with softmax activation function\n",
        "                      nn.Linear(64, 10),\n",
        "                      nn.LogSoftmax(dim = 1)\n",
        "                     )\n",
        "net.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uga_NzQVUZhA",
        "outputId": "20d05dcc-cf27-485b-b63c-76a540978727"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=784, out_features=256, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Dropout(p=0.2, inplace=False)\n",
              "  (3): Linear(in_features=256, out_features=128, bias=True)\n",
              "  (4): ReLU()\n",
              "  (5): Dropout(p=0.2, inplace=False)\n",
              "  (6): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (7): ReLU()\n",
              "  (8): Dropout(p=0.2, inplace=False)\n",
              "  (9): Linear(in_features=64, out_features=10, bias=True)\n",
              "  (10): LogSoftmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Choose an optimizer\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001, weight_decay = 0.001 )\n",
        "\n"
      ],
      "metadata": {
        "id": "j92Z1DYjXEeW"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 10  # suggest training between 20-50 epochs\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    # monitor training loss\n",
        "    train_loss = 0.0\n",
        "    net.train() # prep model for training\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        # Flatten Fashion-MNIST images into a 784 long vector\n",
        "        images = images.view(images.shape[0], -1)\n",
        "        # clear the gradients of all optimized variables\n",
        "        optimizer.zero_grad()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = net(images)\n",
        "        # calculate the loss\n",
        "        loss = criterion(output, labels)\n",
        "        # backward pass: compute gradient of the loss with respect to model parameters\n",
        "        loss.backward()\n",
        "        # perform a single optimization step (parameter update)\n",
        "        optimizer.step()\n",
        "        # update running training loss\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    # print training statistics\n",
        "    # calculate average loss over an epoch\n",
        "    train_loss = train_loss/len(train_loader.dataset)\n",
        "\n",
        "    # Validate\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # set the model to evaluation mode\n",
        "        net.eval()\n",
        "\n",
        "        valid_loss = 0.0\n",
        "        for images, labels in val_loader:\n",
        "            images = images.view(images.shape[0], -1)\n",
        "            # 1. forward pass: compute predicted outputs by passing inputs to the model\n",
        "            output = net(images)  #\n",
        "            # 2. calculate the loss\n",
        "            loss_value = criterion(output, labels)\n",
        "\n",
        "            # Calculate average validation loss\n",
        "            valid_loss = valid_loss + (\n",
        "                (1 / (epoch + 1)) * (loss_value.item() - valid_loss)\n",
        "            )\n",
        "\n",
        "    print(f\"Epoch {epoch+1}: training loss {train_loss:.5f}, valid loss {valid_loss:.5f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzlPg9VKXEhk",
        "outputId": "978f1e93-88ca-4f23-c37d-4c7df20f02a9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: training loss 0.00834, valid loss 0.25640\n",
            "Epoch 2: training loss 0.00411, valid loss 0.11355\n",
            "Epoch 3: training loss 0.00337, valid loss 0.10017\n",
            "Epoch 4: training loss 0.00309, valid loss 0.08557\n",
            "Epoch 5: training loss 0.00289, valid loss 0.09827\n",
            "Epoch 6: training loss 0.00277, valid loss 0.11156\n",
            "Epoch 7: training loss 0.00275, valid loss 0.09764\n",
            "Epoch 8: training loss 0.00255, valid loss 0.10375\n",
            "Epoch 9: training loss 0.00262, valid loss 0.08323\n",
            "Epoch 10: training loss 0.00244, valid loss 0.10797\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "test_loss = 0.0\n",
        "class_correct = list(0.0 for i in range(10))\n",
        "class_total = list(0.0 for i in range(10))\n",
        "\n",
        "net.eval()  # prep model for *evaluation*\n",
        "\n",
        "for images, labels in test_loader:\n",
        "    images = images.view(images.shape[0], -1)\n",
        "    # forward pass: compute predicted outputs by passing inputs to the model\n",
        "    output = net(images)\n",
        "    # calculate the loss\n",
        "    loss = criterion(output, labels)\n",
        "    # update test loss\n",
        "    test_loss += loss.item()\n",
        "    # convert output probabilities to predicted class\n",
        "    _, pred = torch.max(output, 1)\n",
        "    # compare predictions to true label\n",
        "    correct = np.squeeze(pred.eq(labels.view_as(pred)))\n",
        "    # calculate test accuracy for each object class\n",
        "    for i in range(images.shape[0]):\n",
        "        label = labels[i]\n",
        "        class_correct[label] += correct[i].item()\n",
        "        class_total[label] += 1\n",
        "\n",
        "# calculate and print avg test loss\n",
        "test_loss = test_loss / len(test_loader.dataset)\n",
        "print(f\"Test Loss: {test_loss:.6f}\\n\")\n",
        "\n",
        "for i in range(10):\n",
        "    if class_total[i] > 0:\n",
        "        print(\n",
        "            f\"Test Accuracy of {i}: {100 * class_correct[i] / class_total[i]:.2f}%% \"\n",
        "            f\"({int(np.sum(class_correct[i]))}/{int(np.sum(class_total[i]))})\"\n",
        "        )\n",
        "    else:\n",
        "        print(f\"Test Accuracy of {classes[i]}: N/A (no training examples)\")\n",
        "\n",
        "print(\n",
        "    f\"\\nTest Accuracy (Overall): {100.0 * np.sum(class_correct) / np.sum(class_total)}%% \"\n",
        "    f\"({int(np.sum(class_correct))}/{int(np.sum(class_total))})\"\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwlV8-SrXEk3",
        "outputId": "9b407476-679c-425c-cc46-c0fc75165408"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.002170\n",
            "\n",
            "Test Accuracy of 0: 98.98%% (970/980)\n",
            "Test Accuracy of 1: 98.06%% (1113/1135)\n",
            "Test Accuracy of 2: 96.80%% (999/1032)\n",
            "Test Accuracy of 3: 97.23%% (982/1010)\n",
            "Test Accuracy of 4: 92.67%% (910/982)\n",
            "Test Accuracy of 5: 91.82%% (819/892)\n",
            "Test Accuracy of 6: 96.56%% (925/958)\n",
            "Test Accuracy of 7: 98.15%% (1009/1028)\n",
            "Test Accuracy of 8: 93.33%% (909/974)\n",
            "Test Accuracy of 9: 94.95%% (958/1009)\n",
            "\n",
            "Test Accuracy (Overall): 95.94%% (9594/10000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_filename = \"my_model.pth\"\n",
        "\n",
        "# Save the model\n",
        "torch.save(net, model_filename)"
      ],
      "metadata": {
        "id": "kigAwJ3XXErY"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pgc9IaXTXEuK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}